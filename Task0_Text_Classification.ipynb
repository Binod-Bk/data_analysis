{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyB9qtDOXZtn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wMG7YpzDXin6"
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYPL7sSAXjaJ",
    "outputId": "63c3ff86-bd79-43a3-e16a-324f15ba0479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2034\n",
      "Number of categories: 4\n",
      "Categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents: {len(newsgroups_data.data)}\")\n",
    "print(f\"Number of categories: {len(newsgroups_data.target_names)}\")\n",
    "print(\"Categories:\", newsgroups_data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NNWM_k1bXk8j"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups_data.data, newsgroups_data.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ET0jeg85XxMd",
    "outputId": "85196f92-88bd-465f-e062-6d2d515360a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes with CountVectorizer - Accuracy: 0.801, F1-score: 0.801\n",
      "Logistic Regression with CountVectorizer - Accuracy: 0.771, F1-score: 0.768\n",
      "Support Vector Machine with CountVectorizer - Accuracy: 0.501, F1-score: 0.470\n",
      "Decision Tree with CountVectorizer - Accuracy: 0.600, F1-score: 0.604\n"
     ]
    }
   ],
   "source": [
    "algorithms = {\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in algorithms.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    results.append((name, 'CountVectorizer', accuracy, f1))\n",
    "    print(f\"{name} with CountVectorizer - Accuracy: {accuracy:.3f}, F1-score: {f1:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39UYc2jcXxTm",
    "outputId": "45c6b383-d937-4fd6-d48d-bb12790ac96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes with TfidfTransformer - Accuracy: 0.749, F1-score: 0.695\n",
      "Logistic Regression with TfidfTransformer - Accuracy: 0.811, F1-score: 0.803\n",
      "Support Vector Machine with TfidfTransformer - Accuracy: 0.779, F1-score: 0.772\n",
      "Decision Tree with TfidfTransformer - Accuracy: 0.582, F1-score: 0.573\n"
     ]
    }
   ],
   "source": [
    "for name, model in algorithms.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    results.append((name, 'TfidfTransformer', accuracy, f1))\n",
    "    print(f\"{name} with TfidfTransformer - Accuracy: {accuracy:.3f}, F1-score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VE30ud2wXxWw",
    "outputId": "3208c09a-0b10-484c-b41e-83dce3732d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Word2Vec - Accuracy: 0.484, F1-score: 0.437\n",
      "Support Vector Machine with Word2Vec - Accuracy: 0.428, F1-score: 0.382\n",
      "Decision Tree with Word2Vec - Accuracy: 0.373, F1-score: 0.372\n"
     ]
    }
   ],
   "source": [
    "X_train_tokenized = [doc.split() for doc in X_train]\n",
    "X_test_tokenized = [doc.split() for doc in X_test]\n",
    "\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=X_train_tokenized, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "def get_avg_word2vec_vectors(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "X_train_w2v = np.array([get_avg_word2vec_vectors(doc, word2vec_model) for doc in X_train_tokenized])\n",
    "X_test_w2v = np.array([get_avg_word2vec_vectors(doc, word2vec_model) for doc in X_test_tokenized])\n",
    "\n",
    "\n",
    "for name, model in algorithms.items():\n",
    "    if name == 'Multinomial Naive Bayes':\n",
    "        continue  \n",
    "    model.fit(X_train_w2v, y_train)\n",
    "    y_pred = model.predict(X_test_w2v)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    results.append((name, 'Word2Vec', accuracy, f1))\n",
    "    print(f\"{name} with Word2Vec - Accuracy: {accuracy:.3f}, F1-score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHRY9WQBXxaS",
    "outputId": "3718ce34-397b-45f2-e1aa-00c2b591cfaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Doc2Vec - Accuracy: 0.676, F1-score: 0.669\n",
      "Support Vector Machine with Doc2Vec - Accuracy: 0.654, F1-score: 0.631\n",
      "Decision Tree with Doc2Vec - Accuracy: 0.501, F1-score: 0.497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_tagged = [TaggedDocument(words=doc.split(), tags=[i]) for i, doc in enumerate(X_train)]\n",
    "X_test_tagged = [TaggedDocument(words=doc.split(), tags=[i]) for i, doc in enumerate(X_test)]\n",
    "\n",
    "doc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=2, workers=4, epochs=20)\n",
    "doc2vec_model.build_vocab(X_train_tagged)\n",
    "doc2vec_model.train(X_train_tagged, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "X_train_d2v = np.array([doc2vec_model.infer_vector(doc.words) for doc in X_train_tagged])\n",
    "X_test_d2v = np.array([doc2vec_model.infer_vector(doc.words) for doc in X_test_tagged])\n",
    "\n",
    "for name, model in algorithms.items():\n",
    "    if name == 'Multinomial Naive Bayes':\n",
    "        continue \n",
    "    model.fit(X_train_d2v, y_train)\n",
    "    y_pred = model.predict(X_test_d2v)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    results.append((name, 'Doc2Vec', accuracy, f1))\n",
    "    print(f\"{name} with Doc2Vec - Accuracy: {accuracy:.3f}, F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CWnzMMDv47o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
